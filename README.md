# My Web Scraper :cloud:  
#### Python scripts to scrape Covid-19 cases data from [COVID-19 Central @ The U](https://coronavirus.utah.edu)   
The purpose of this is to keep track of the timeline, daily increases/decreases in the data they provide.  
 

* Scheduled scrape time: Daily at 9AM, 11:30AM, 12:30PM, 2:30PM and 6:00PM in MDT. :penguin:

#### Visit folder ```data/``` for the csv files  
* [Un-processed data from the covid cases panel](https://github.com/baohuy251210/Collector/blob/master/data/uofucovidinit_timeline.csv)  
* [Processed cumulative case counts On Campus since 8/15/20](https://github.com/baohuy251210/Collector/blob/master/data/cases_timeline.csv)  

*Since there's not many details, this is all the scripts can get right now.* 
